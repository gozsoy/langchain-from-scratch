{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "from dotenv import load_dotenv\n",
    "import arxiv\n",
    "from openai import OpenAI\n",
    "\n",
    "# parse .env file and load all variables\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# initialize open ai client for api calls\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation Memories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A- ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"System: This is a conversation between a software engineer and intellectual AI bot. AI bot is talkative and teaches concepts to the engineer.\n",
    "Current Conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "\n",
    "history = ''\n",
    "\n",
    "def talk(question):\n",
    "\n",
    "    global history\n",
    "    \n",
    "    # put current values of the variables into prompt string\n",
    "    prompt_after_formatting = prompt.format(input=question,\n",
    "                                            history=history)\n",
    "\n",
    "    # make API call\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt_after_formatting}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # processing open ai's response\n",
    "    output = completion.choices[0].message.content\n",
    "\n",
    "    # my way of adding human and ai messages into history\n",
    "    history += f\"Human: {question}\\nAI: {output}\\n\"\n",
    "\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: This is a conversation between a software engineer and intellectual AI bot. AI bot is talkative and teaches concepts to the engineer.\n",
      "Current Conversation:\n",
      "Human: Do you know anything about OOP?\n",
      "AI: Yes, Object-Oriented Programming (OOP) is a programming paradigm that revolves around the concept of objects, which can contain data in the form of fields (attributes or properties) and code in the form of procedures (methods). OOP focuses on organizing code into reusable, modular components, allowing for easier maintenance and scalability. Is there a specific aspect of OOP you'd like more information on?\n",
      "Human: Sorry. What did I ask you?\n",
      "AI: You asked me if I know anything about OOP (Object-Oriented Programming).\n",
      "Human: What is SQL?\n",
      "AI: SQL stands for Structured Query Language, and it is used to communicate with and manipulate databases. SQL allows users to perform tasks such as retrieving data, creating, updating, and deleting records, and managing a database's structure. It is a standard language for interacting with relational databases and is essential for anyone working with data management and storage. Is there a specific aspect of SQL you'd like to know more about?\n",
      "\n",
      "Human: current question\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "talk(\"Do you know anything about OOP?\")\n",
    "talk(\"Sorry. What did I ask you?\")\n",
    "talk(\"What is SQL?\")\n",
    "print(prompt.format(input=\"current question\",history=history))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B- ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"System: This is a conversation between a software engineer and intellectual AI bot. AI bot is talkative and teaches concepts to the engineer.\n",
    "Current Conversation Summary:\n",
    "{summary}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "\n",
    "summary_prompt = \"\"\"System: Your task is to summarize below conversation with emphasis on key points. If nothing given, return ''.\n",
    "{history}\n",
    "Summary:\"\"\"\n",
    "\n",
    "history = ''\n",
    "\n",
    "def talk(question):\n",
    "\n",
    "    global history\n",
    "\n",
    "    # put history variable into summary prompt string\n",
    "    summary_prompt_after_formatting = summary_prompt.format(history=history)\n",
    "\n",
    "    # make API call for summarization\n",
    "    summary_completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": summary_prompt_after_formatting}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # processing open ai's response\n",
    "    summary = summary_completion.choices[0].message.content\n",
    "\n",
    "    # put current values of the variables into prompt string\n",
    "    prompt_after_formatting = prompt.format(input=question,\n",
    "                                            summary=summary)\n",
    "    \n",
    "    # make API call for answering question\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt_after_formatting}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # processing open ai's response\n",
    "    output = completion.choices[0].message.content\n",
    "    print(prompt_after_formatting)\n",
    "    # my way of adding human and ai messages into history\n",
    "    history += f\"Human: {question}\\nAI: {output}\\n\"\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: This is a conversation between a software engineer and intellectual AI bot. AI bot is talkative and teaches concepts to the engineer.\n",
      "Current Conversation Summary:\n",
      "The conversation between the human and the AI touched on topics such as the AI's well-being, familiarity with football, England's first participation in the Euros in 1968, and other teams in the same competition. The key points highlighted include the structure of football, England's performance in the 1968 Euros, and the other teams involved in the tournament.\n",
      "Human: How are you today?\n",
      "AI:\n",
      "System: This is a conversation between a software engineer and intellectual AI bot. AI bot is talkative and teaches concepts to the engineer.\n",
      "Current Conversation Summary:\n",
      "The conversation involved the AI answering questions about football, specifically about England's first participation in the Euros in 1968 and the other teams in the competition. The AI also mentioned that it is functioning well and ready to assist.\n",
      "Human: Sorry. What did I ask you?\n",
      "AI:\n",
      "System: This is a conversation between a software engineer and intellectual AI bot. AI bot is talkative and teaches concepts to the engineer.\n",
      "Current Conversation Summary:\n",
      "The conversation started with the human asking how the AI was doing, followed by questions about football and when England first competed in the Euros. The AI provided information on England's participation in the 1968 Euros and the other teams in the competition. The AI then reiterated the details and mentioned how the tournament format has evolved over the years. Lastly, the human asked again what they had asked, and the AI summarized the previous questions about the Euros.\n",
      "Human: do you know about football?\n",
      "AI:\n",
      "System: This is a conversation between a software engineer and intellectual AI bot. AI bot is talkative and teaches concepts to the engineer.\n",
      "Current Conversation Summary:\n",
      "The conversation includes questions about the AI's knowledge of football, specifically England's first participation in the Euros in 1968 and the other teams in the competition. The AI provides information on these topics, including the format of the competition evolving over the years. The AI emphasizes its readiness to assist with any questions related to football.\n",
      "Human: when did england compete in euros first?\n",
      "AI:\n",
      "System: This is a conversation between a software engineer and intellectual AI bot. AI bot is talkative and teaches concepts to the engineer.\n",
      "Current Conversation Summary:\n",
      "The conversation includes inquiries about the AI's knowledge of football and the Euros, specifically when England competed in the Euros for the first time in 1968 and the other teams that participated in the same competition. The AI provides detailed information about the tournament and the teams involved. It also emphasizes that it is ready to assist with any other questions related to football history or the Euros.\n",
      "Human: what were the other teams in the same competition?\n",
      "AI:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In the 1968 European Championship, besides England, the other teams that competed were Italy, Yugoslavia, and the Soviet Union. Italy emerged as the champions of the tournament after defeating Yugoslavia in the final. If you have any more questions about the competition or football history, feel free to ask!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talk(\"How are you today?\")\n",
    "talk(\"Sorry. What did I ask you?\")\n",
    "talk(\"do you know about football?\")\n",
    "talk(\"when did england compete in euros first?\")\n",
    "talk(\"what were the other teams in the same competition?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function-Use (Agents and Tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arxiv_search(args):\n",
    "    # Construct the default API client.\n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Search for the paper with ID\n",
    "    search_by_id = arxiv.Search(query=args['query'],\n",
    "                                id_list=[args['id']])\n",
    "    # Reuse client to fetch the paper, then print its title.\n",
    "    first_result = next(client.results(search_by_id))\n",
    "    \n",
    "    return first_result.title\n",
    "\n",
    "def convert_time(args):\n",
    "    temp = args['time'].split(':')\n",
    "\n",
    "    return int(temp[0])*3600 + int(temp[1])*60 + int(temp[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "ALWAYS use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do. only one action at a time.\n",
    "Action: the action to take, should be one of {tool_names}\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Reminder to ALWAYS use the exact characters `Final Answer:` when you provide a definitive answer.\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\"\"\"\n",
    "\n",
    "tools = {\n",
    "    'convert_time': 'A function to convert a time string with format H:MM:SS to seconds, args: {\"time\": {\"type\": \"string\"}}',\n",
    "    'arxiv_search': 'A function to get information about a scientific article or articles, args: {\"query\": {\"type\": \"string\"}, \"id\": {\"type\": \"string\"}}'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_scratchpad = ''\n",
    "\n",
    "def ask(question):\n",
    "\n",
    "    global agent_scratchpad\n",
    "\n",
    "    # convert function description into suitable string for prompt\n",
    "    tools_str = ''\n",
    "    for func, desc in tools.items():\n",
    "        tools_str += f\"{func} : {desc}\\n\"\n",
    "    \n",
    "    # put current values of the variables into prompt string\n",
    "    prompt_after_formatting = system_prompt.format(input=question, \n",
    "                                                   agent_scratchpad=agent_scratchpad, \n",
    "                                                   tools=tools_str, \n",
    "                                                   tool_names=list(tools.keys()))\n",
    "    print(prompt_after_formatting)\n",
    "\n",
    "    #  make API call for answering question\n",
    "    # stop generation when see Observation:\n",
    "    # as it signs that we need a call a function externally\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt_after_formatting}\n",
    "        ],\n",
    "        stop=[\"Observation:\"]\n",
    "    )\n",
    "\n",
    "    # processing open ai's response\n",
    "    output = completion.choices[0].message.content\n",
    "    print(output)\n",
    "    \n",
    "    # keep reasoning until see Final Answer: string\n",
    "    while output.find(\"Final Answer: \")==-1:\n",
    "\n",
    "        # append previous reasoning step\n",
    "        agent_scratchpad += output\n",
    "\n",
    "        # parse LLM output string into function and its arguments\n",
    "        function_name = output.split(\"Action: \")[1].split('\\n')[0]\n",
    "        function_args = ast.literal_eval(output.split(\"Action Input: \")[1].split('\\n')[0])\n",
    "\n",
    "        # call function externally\n",
    "        result = globals()[function_name](function_args)\n",
    "\n",
    "        # append function output to logs\n",
    "        agent_scratchpad += f\"Observation: {result}\\n\"\n",
    "        print(f\"Observation: {result}\\n\")\n",
    "        \n",
    "        # put current values of the variables into prompt string\n",
    "        prompt_after_formatting = system_prompt.format(input=question, \n",
    "                                                    agent_scratchpad=agent_scratchpad, \n",
    "                                                    tools=tools_str, \n",
    "                                                    tool_names=list(tools.keys()))\n",
    "        \n",
    "        # make the next API call, this time with the result of \n",
    "        # previously requested function by LLM \n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt_after_formatting}\n",
    "            ],\n",
    "            stop=[\"Observation:\"]\n",
    "        )\n",
    "\n",
    "        # processing open ai's response\n",
    "        output = completion.choices[0].message.content\n",
    "        \n",
    "        print(output)  \n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "convert_time : A function to convert a time string with format H:MM:SS to seconds, args: {\"time\": {\"type\": \"string\"}}\n",
      "arxiv_search : A function to get information about a scientific article or articles, args: {\"query\": {\"type\": \"string\"}, \"id\": {\"type\": \"string\"}}\n",
      "\n",
      "\n",
      "ALWAYS use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do. only one action at a time.\n",
      "Action: the action to take, should be one of ['convert_time', 'arxiv_search']\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Reminder to ALWAYS use the exact characters `Final Answer:` when you provide a definitive answer.\n",
      "\n",
      "Question: how many seconds in 4:00:01. What's the paper 2311.01606 about?\n",
      "Thought:I need to convert the time 4:00:01 to seconds first before searching for the paper.\n",
      "Action: convert_time\n",
      "Action Input: {\"time\": \"4:00:01\"}\n",
      "Observation: 14401\n",
      "Action: arxiv_search\n",
      "Action Input: {\"query\": \"\", \"id\": \"2311.01606\"}\n",
      "Observation: KG-FRUS: a Novel Graph-based Dataset of 127 Years of US Diplomatic Relations\n",
      "\n",
      "Final Answer: 14401 seconds. The paper 2311.01606 is about \"KG-FRUS: a Novel Graph-based Dataset of 127 Years of US Diplomatic Relations\".\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Final Answer: 14401 seconds. The paper 2311.01606 is about \"KG-FRUS: a Novel Graph-based Dataset of 127 Years of US Diplomatic Relations\".'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"how many seconds in 4:00:01. What's the paper 2311.01606 about?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
