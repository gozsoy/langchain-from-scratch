{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "from dotenv import load_dotenv\n",
    "import arxiv\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatOpenAI( model_kwargs={\"stop\": [\"Observation:\"]},)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation Memories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A- ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"System: This is a conversation between a software engineer and intellectual AI bot. AI bot is talkative and teaches concepts to the engineer.\n",
    "Current Conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "\n",
    "history = ''\n",
    "\n",
    "def talk(question):\n",
    "\n",
    "    global history\n",
    "    \n",
    "    prompt_after_formatting = prompt.format(input=question,\n",
    "                                            history=history)\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt_after_formatting}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    output = completion.choices[0].message.content\n",
    "\n",
    "    history += f\"Human: {question}\\nAI: {output}\\n\"\n",
    "\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: This is a conversation between a software engineer and intellectual AI bot. AI bot is talkative and teaches concepts to the engineer.\n",
      "Current Conversation:\n",
      "Human: How are you today?\n",
      "AI: I'm doing well, thank you for asking! I've been learning more about machine learning algorithms today. Did you know that neural networks are inspired by the way the human brain processes information? It's fascinating how technology can mimic biological processes.\n",
      "Human: Sorry. What did I ask you?\n",
      "AI: You asked me how I was doing today. And I shared with you that I've been learning more about machine learning algorithms, specifically neural networks inspired by the human brain. It's amazing how technology can replicate biological processes, don't you think?\n",
      "Human: Do you know anything about football?\n",
      "AI: Yes, I know about football! It's a popular sport played around the world. The rules of the game involve two teams trying to score goals by getting the ball into the opposing team's goal using any part of their body except their hands and arms. It requires a combination of physical skill, strategic thinking, and teamwork to be successful in football. It's a great example of how complex systems can work together towards a common goal.\n",
      "\n",
      "Human: current question\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "talk(\"How are you today?\")\n",
    "talk(\"Sorry. What did I ask you?\")\n",
    "talk(\"Do you know anything about football?\")\n",
    "print(prompt.format(input=\"current question\",history=history))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B- ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"System: This is a conversation between a software engineer and intellectual AI bot. AI bot is talkative and teaches concepts to the engineer.\n",
    "Current Conversation Summary:\n",
    "{summary}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "\n",
    "summary_prompt = \"\"\"System: Your task is to summarize below conversation with emphasis on key points. If nothing given, return ''.\n",
    "{history}\n",
    "Summary:\"\"\"\n",
    "\n",
    "history = ''\n",
    "\n",
    "def talk(question):\n",
    "\n",
    "    global history\n",
    "\n",
    "    summary_prompt_after_formatting = summary_prompt.format(history=history)\n",
    "\n",
    "    summary_completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": summary_prompt_after_formatting}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    summary = summary_completion.choices[0].message.content\n",
    "\n",
    "    prompt_after_formatting = prompt.format(input=question,\n",
    "                                            summary=summary)\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt_after_formatting}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    output = completion.choices[0].message.content\n",
    "    print(prompt_after_formatting)\n",
    "    history += f\"Human: {question}\\nAI: {output}\\n\"\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: This is a conversation between a software engineer and intellectual AI bot. AI bot is talkative and teaches concepts to the engineer.\n",
      "Current Conversation Summary:\n",
      "\"Nothing.\"\n",
      "Human: How are you today?\n",
      "AI:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm doing well, thank you for asking. How can I assist you today?\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talk(\"How are you today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: This is a conversation between a software engineer and intellectual AI bot. AI bot is talkative and teaches concepts to the engineer.\n",
      "Current Conversation Summary:\n",
      "AI is doing well and ready to assist the human with any task.\n",
      "Human: Sorry. What did I ask you?\n",
      "AI:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You asked me to explain the concept of object-oriented programming and how it can be applied in software development. Would you like me to go over that again for you?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talk(\"Sorry. What did I ask you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: This is a conversation between a software engineer and intellectual AI bot. AI bot is talkative and teaches concepts to the engineer.\n",
      "Current Conversation Summary:\n",
      "The AI explained that it is doing well and asked how it can assist the human. The human asked the AI to explain the concept of object-oriented programming and how it can be applied in software development.\n",
      "Human: do you know about football?\n",
      "AI:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, I am aware of football. It is a popular sport played worldwide. Would you like to know more about it or how it relates to our conversation?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talk(\"do you know about football?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: This is a conversation between a software engineer and intellectual AI bot. AI bot is talkative and teaches concepts to the engineer.\n",
      "Current Conversation Summary:\n",
      "The human asked the AI how it was doing and then inquired about football. The AI offered to assist with explaining object-oriented programming in software development but the human did not pursue that topic further.\n",
      "Human: when did england compete in euros first?\n",
      "AI:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'England first competed in the UEFA European Championship (Euros) in 1968.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talk(\"when did england compete in euros first?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: This is a conversation between a software engineer and intellectual AI bot. AI bot is talkative and teaches concepts to the engineer.\n",
      "Current Conversation Summary:\n",
      "The conversation covers topics ranging from the AI's readiness to assist, object-oriented programming, football, and England's first participation in the UEFA European Championship in 1968.\n",
      "Human: what were the other teams in the same competition?\n",
      "AI:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In the 1968 UEFA European Championship, the other teams that participated were the Soviet Union, Yugoslavia, and Italy. England was the eventual winners of the tournament, defeating the Soviet Union in the final.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talk(\"what were the other teams in the same competition?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function-Use (Agents and Tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arxiv_search(args):\n",
    "    # Construct the default API client.\n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Search for the paper with ID\n",
    "    search_by_id = arxiv.Search(query=args['query'],\n",
    "                                id_list=[args['id']])\n",
    "    # Reuse client to fetch the paper, then print its title.\n",
    "    first_result = next(client.results(search_by_id))\n",
    "    \n",
    "    return first_result.title\n",
    "\n",
    "def convert_time(args):\n",
    "    temp = args['time'].split(':')\n",
    "\n",
    "    return int(temp[0])*3600 + int(temp[1])*60 + int(temp[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "ALWAYS use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do. only one action at a time.\n",
    "Action: the action to take, should be one of {tool_names}\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Reminder to ALWAYS use the exact characters `Final Answer:` when you provide a definitive answer.\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\"\"\"\n",
    "\n",
    "tools = {\n",
    "    'convert_time': 'A function to convert a time string with format H:MM:SS to seconds, args: {\"time\": {\"type\": \"string\"}}',\n",
    "    'arxiv_search': 'A function to get information about a scientific article or articles, args: {\"query\": {\"type\": \"string\"}, \"id\": {\"type\": \"string\"}}'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_scratchpad = ''\n",
    "\n",
    "def ask(question):\n",
    "\n",
    "    global agent_scratchpad\n",
    "\n",
    "    tools_str = ''\n",
    "\n",
    "    for func, desc in tools.items():\n",
    "        tools_str += f\"{func} : {desc}\\n\"\n",
    "    \n",
    "    prompt_after_formatting = system_prompt.format(input=question, \n",
    "                                                   agent_scratchpad=agent_scratchpad, \n",
    "                                                   tools=tools_str, \n",
    "                                                   tool_names=list(tools.keys()))\n",
    "    print(prompt_after_formatting)\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt_after_formatting}\n",
    "        ],\n",
    "        stop=[\"Observation:\"]\n",
    "    )\n",
    "    output = completion.choices[0].message.content\n",
    "    print(output)\n",
    "    \n",
    "    while output.find(\"Final Answer: \")==-1:\n",
    "\n",
    "        agent_scratchpad += output\n",
    "\n",
    "        function_name = output.split(\"Action: \")[1].split('\\n')[0]\n",
    "        function_args = ast.literal_eval(output.split(\"Action Input: \")[1].split('\\n')[0])\n",
    "\n",
    "        result = globals()[function_name](function_args)\n",
    "        agent_scratchpad += f\"Observation: {result}\\n\"\n",
    "        print(f\"Observation: {result}\\n\")\n",
    "        \n",
    "        prompt_after_formatting = system_prompt.format(input=question, \n",
    "                                                    agent_scratchpad=agent_scratchpad, \n",
    "                                                    tools=tools_str, \n",
    "                                                    tool_names=list(tools.keys()))\n",
    "        \n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt_after_formatting}\n",
    "            ],\n",
    "            stop=[\"Observation:\"]\n",
    "        )\n",
    "        output = completion.choices[0].message.content\n",
    "        \n",
    "        print(output)  \n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "convert_time : A function to convert a time string with format H:MM:SS to seconds, args: {\"time\": {\"type\": \"string\"}}\n",
      "arxiv_search : A function to get information about a scientific article or articles, args: {\"query\": {\"type\": \"string\"}, \"id\": {\"type\": \"string\"}}\n",
      "\n",
      "\n",
      "ALWAYS use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do. only one action at a time.\n",
      "Action: the action to take, should be one of ['convert_time', 'arxiv_search']\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Reminder to ALWAYS use the exact characters `Final Answer:` when you provide a definitive answer.\n",
      "\n",
      "Question: First answer how many seconds in 4:00:01. Then answer What's the paper 1605.08386 about?\n",
      "Thought:\n",
      "We need to convert the time first and then search for the paper.\n",
      "Action: convert_time\n",
      "Action Input: {\"time\": \"4:00:01\"}\n",
      "\n",
      "Observation: 14401\n",
      "\n",
      "Action: arxiv_search\n",
      "Action Input: {\"query\": \"\", \"id\": \"1605.08386\"}\n",
      "\n",
      "Observation: Heat-bath random walks with Markov bases\n",
      "\n",
      "Final Answer: The time 4:00:01 is equivalent to 14401 seconds. The paper 1605.08386 is about Heat-bath random walks with Markov bases.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Final Answer: The time 4:00:01 is equivalent to 14401 seconds. The paper 1605.08386 is about Heat-bath random walks with Markov bases.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"First answer how many seconds in 4:00:01. Then answer What's the paper 1605.08386 about?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
